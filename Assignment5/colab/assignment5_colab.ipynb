{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai langchain-openai langchain-community pypdf chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "import warnings\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# CHROMA_PATH = os.path.join(os.getcwd(), \"Assignment5\", \"colab\", \"chroma_db\")\n",
    "CHROMA_PATH = os.path.join(os.getcwd(), \"chroma_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If getting upgrade warning, run the following from command line: \n",
    "\n",
    "chroma utils vacuum --path chroma_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file):\n",
    "    import os\n",
    "    name, extension = os.path.splitext(file)\n",
    "\n",
    "    if extension == '.pdf':\n",
    "        from langchain_community.document_loaders import PyPDFLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = PyPDFLoader(file)\n",
    "    elif extension == '.docx':\n",
    "        from langchain.document_loaders import Docx2txtLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = Docx2txtLoader(file)\n",
    "    elif extension == '.txt':\n",
    "        from langchain.document_loaders import TextLoader\n",
    "        loader = TextLoader(file)\n",
    "    else:\n",
    "        print('Document format is not supported!')\n",
    "        return None\n",
    "\n",
    "    data = loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_wikipedia(query, lang='en', load_max_docs=2):\n",
    "    from langchain_community.document_loaders import WikipediaLoader\n",
    "    loader = WikipediaLoader(query=query, lang=lang, load_max_docs=load_max_docs)\n",
    "    data = loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data, chunk_size=256):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_chroma(chunks, persist_directory=CHROMA_PATH):\n",
    "    from langchain_community.vectorstores import Chroma\n",
    " \n",
    "    # Instantiate an embedding model from Azure OpenAI\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        api_key=\"3a93fe43c4534148a7a193412e29a321\",\n",
    "        api_version=\"2024-02-01\",\n",
    "        azure_endpoint=\"https://ey-openai.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-05-15\"\n",
    "    )\n",
    "\n",
    "    # Create a Chroma vector store using the provided text chunks and embedding model, \n",
    "    # configuring it to save data to the specified directory \n",
    "    vector_store = Chroma.from_documents(chunks, embeddings, persist_directory=persist_directory) \n",
    "\n",
    "    return vector_store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_chroma(persist_directory=CHROMA_PATH):\n",
    "    from langchain.vectorstores import Chroma\n",
    "\n",
    "    # Instantiate the same embedding model used during creation\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        api_key=\"3a93fe43c4534148a7a193412e29a321\",\n",
    "        api_version=\"2024-02-01\",\n",
    "        azure_endpoint=\"https://ey-openai.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-05-15\"\n",
    "    )\n",
    "\n",
    "    # Load the Chroma vector store from the specified directory, using the provided embedding function\n",
    "    vector_store = Chroma(persist_directory=persist_directory, embedding_function=embeddings) \n",
    "\n",
    "    return vector_store  # Return the loaded vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_and_get_answer(vector_store, q, k=3):\n",
    "    from langchain.chains import RetrievalQA\n",
    "\n",
    "    llm = AzureChatOpenAI(temperature=0,\n",
    "                      api_key=\"3a93fe43c4534148a7a193412e29a321\",\n",
    "                      api_version=\"2024-02-01\",\n",
    "                      azure_endpoint=\"https://ey-openai.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-03-15-preview\",\n",
    "                      model=\"gpt-35-turbo\"\n",
    "            )\n",
    "\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': k})\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "    \n",
    "    answer = chain.invoke(q)\n",
    "    return answer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a directory exists\n",
    "if os.path.exists(CHROMA_PATH):\n",
    "    # os.rmdir(CHROMA_PATH)\n",
    "    shutil.rmtree(CHROMA_PATH)\n",
    "    print('deleted ' + CHROMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading c:\\Users\\GX171TT\\OneDrive - EY\\Documents\\Notes\\2024\\Oct24\\GENAI\\Assignment5\\colab\\files\\Personal Note.pdf\n"
     ]
    }
   ],
   "source": [
    "# Loading the pdf document into LangChain \n",
    "# data = load_document(os.path.join( os.getcwd(), 'Assignment5','colab','files', 'Personal Note.pdf'))\n",
    "data = load_document(os.path.join( os.getcwd(),'files', 'Personal Note.pdf'))\n",
    "\n",
    "# print(data)\n",
    "# Load the document from Wikipedia\n",
    "# data = load_from_wikipedia(\"Amitabh Bacchan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the document into chunks\n",
    "chunks = chunk_data(data)\n",
    "\n",
    "# print(chunks)\n",
    "# Creating a Chroma vector store using the provided text chunks and embedding model (default is text-embedding-3-small)\n",
    "vector_store = create_embeddings_chroma(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Summarize the whole input in 150 words', 'result': \"The writer begins by describing their visit to Marina Beach, an iconic destination in Chennai, India. They mention the breathtaking view of the Bay of Bengal and the refreshing experience of feeling the cool breeze and watching the waves crash onto the shore. In the evening, they visit Mahabalipuram Beach, where they enjoy the peaceful atmosphere and witness a beautiful sunset. The writer expresses their gratitude for the opportunity to explore such a culturally rich and diverse region, and they mention that the vacation has left a lasting impression on their heart. They return home with cherished memories of the ancient town and its historical significance. Overall, the writer's trip to Chennai has been a memorable and enriching experience.\"}\n"
     ]
    }
   ],
   "source": [
    "# Asking questions\n",
    "q = 'Summarize the whole input in 150 words'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
